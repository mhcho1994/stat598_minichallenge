{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT59800 Minichallenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the packages required\n",
    "run only once when you first launch the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# install required packages\n",
    "# pip package upgrade (for opencv download)\n",
    "# tensorflow, keras, jupyter (ipykernel) are already installed in this container\n",
    "# only run once when setting up an environment\n",
    "\n",
    "# pip upgrade\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# install the dependencies of VGGFace2\n",
    "!pip install git+https://github.com/yaledhlab/vggface.git\n",
    "    \n",
    "# this part will takes more than 5mins (check \"opencv-python\\nSuccessfully installed opencv-python-4.9.0.80\")\n",
    "import subprocess\n",
    "\n",
    "cmd = [\"apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\", \\\n",
    "       \"apt-get update\", \"apt-get install -y libgl1\", \"pip install opencv-python\"]\n",
    "\n",
    "for sub_cmd in cmd:\n",
    "    runcmd = subprocess.Popen(sub_cmd, stdout = subprocess.PIPE, shell = True)\n",
    "    [out, err] = runcmd.communicate()\n",
    "    print(out)\n",
    "\n",
    "# pip install other packages\n",
    "!pip install natsort \n",
    "!pip install mtcnn \n",
    "!pip install pandas \n",
    "!pip install tqdm\n",
    "!pip install keras_applications\n",
    "!pip install scikit-learn\n",
    "!pip install datatable\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the packages required for the script\n",
    "load the packages for running the script and checking GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# common\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import datatable as dt\n",
    "\n",
    "# pre-processing (face-recognition)\n",
    "import cv2\n",
    "import glob\n",
    "import natsort\n",
    "from PIL import Image\n",
    "from mtcnn import MTCNN\n",
    "from itertools import combinations\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# face-identification\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing \\\n",
    "import RandomTranslation, RandomRotation, RandomFlip, RandomZoom, RandomContrast\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "\n",
    "# evaluation & training\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay, CosineDecay, CosineDecayRestarts\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# miscellaneous\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.metrics import structural_similarity\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'=\"0\"]\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of the images and labels\n",
    "create the directories for saving the processed images \\\n",
    "using MTCNN to crop faces in the given images \\\n",
    "discard and classify problematic images separately \\\n",
    "(problmatic images: unreadable, undetectable, multiface/low confidence, low similarity) \\\n",
    "pre-process the test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable dir_empty option if want to delete the existing classified images\n",
    "def create_preprocess_path(train_img_process_path, \\\n",
    "            train_img_suspect_path, train_img_lowconf_path, train_img_multiface_path, train_img_lowsimilar_path, \\\n",
    "            train_img_unprocess_path, train_img_unread_path, train_img_undetect_path, \\\n",
    "            test_img_process_path, test_img_unprocess_path, test_img_suspect_path, \\\n",
    "            train_img_data_path, test_img_data_path, dir_empty = False, parent_dir = r'tf'):\n",
    "    \n",
    "    if dir_empty:\n",
    "        try: \n",
    "            shutil.rmtree(train_img_process_path)\n",
    "        except:\n",
    "            pass\n",
    "        try: \n",
    "            shutil.rmtree(train_img_suspect_path) \n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(train_img_unprocess_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(test_img_process_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(test_img_unprocess_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(test_img_suspect_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(train_img_data_path)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            shutil.rmtree(test_img_data_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # create the directories if they are not existing\n",
    "    if not os.path.exists(train_img_process_path):\n",
    "        os.makedirs(train_img_process_path)\n",
    "\n",
    "    if not os.path.exists(os.path.join(train_img_unprocess_path,train_img_unread_path)):\n",
    "        os.makedirs(os.path.join(train_img_unprocess_path,train_img_unread_path), exist_ok = True)\n",
    "\n",
    "    if not os.path.exists(os.path.join(train_img_unprocess_path,train_img_undetect_path)):\n",
    "        os.makedirs(os.path.join(train_img_unprocess_path,train_img_undetect_path), exist_ok = True)\n",
    "\n",
    "    if not os.path.exists(os.path.join(train_img_suspect_path,train_img_lowconf_path)):\n",
    "        os.makedirs(os.path.join(train_img_suspect_path,train_img_lowconf_path), exist_ok = True)\n",
    "\n",
    "    if not os.path.exists(os.path.join(train_img_suspect_path,train_img_multiface_path)):\n",
    "        os.makedirs(os.path.join(train_img_suspect_path,train_img_multiface_path), exist_ok = True)\n",
    "\n",
    "    if not os.path.exists(os.path.join(train_img_suspect_path,train_img_lowsimilar_path)):\n",
    "        os.makedirs(os.path.join(train_img_suspect_path,train_img_lowsimilar_path), exist_ok = True)\n",
    "        \n",
    "    if not os.path.exists(test_img_process_path):\n",
    "        os.makedirs(test_img_process_path)\n",
    "        \n",
    "    if not os.path.exists(test_img_unprocess_path):\n",
    "        os.makedirs(test_img_unprocess_path)\n",
    "        \n",
    "    if not os.path.exists(test_img_suspect_path):\n",
    "        os.makedirs(test_img_suspect_path)\n",
    "\n",
    "    if not os.path.exists(train_img_data_path):\n",
    "        os.makedirs(train_img_data_path)\n",
    "        \n",
    "    if not os.path.exists(test_img_data_path):\n",
    "        os.makedirs(test_img_data_path)\n",
    "\n",
    "# create directory for saving training data\n",
    "def create_train_path(training_results_path, \\\n",
    "            training_model_save_path, training_results_ckpt_path, \\\n",
    "            dir_empty = False, parent_dir = r'tf'):\n",
    "    \n",
    "    if dir_empty:\n",
    "        try:\n",
    "            shutil.rmtree(training_results_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # create the directories if they are not existing\n",
    "    if not os.path.exists(os.path.join(training_results_path,training_model_save_path)):\n",
    "        os.makedirs(os.path.join(training_results_path,training_model_save_path))\n",
    "\n",
    "    if not os.path.exists(os.path.join(training_results_path,training_results_ckpt_path)):\n",
    "        os.makedirs(os.path.join(training_results_path,training_results_ckpt_path))\n",
    "        \n",
    "# crop faces from the image using the result of MTCNN\n",
    "def cropface(frame,results,idx):\n",
    "\n",
    "    # set the coordinates of the bounding box\n",
    "    x_bl_corner, y_bl_corner, box_width, box_height = results[idx]['box']\n",
    "    x_tr_corner = x_bl_corner+box_width\n",
    "    y_tr_corner = y_bl_corner+box_height\n",
    "\n",
    "    # get the bounding box image for the detected face\n",
    "    raw_face = frame[y_bl_corner:y_tr_corner, x_bl_corner:x_tr_corner]\n",
    "\n",
    "    # resize the image to conform the input size of VGGFace2 model \n",
    "    resized_face  = cv2.resize(raw_face, dsize = (224,224), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    return resized_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current working directory to the path \n",
    "docker_parent_dir = r'/tf'\n",
    "os.chdir(docker_parent_dir)\n",
    "\n",
    "# label data path\n",
    "label_dict_path = 'ws/labels/category.csv'\n",
    "train_label_path = 'ws/labels/train.csv'\n",
    "test_label_path = 'ws/labels'\n",
    "\n",
    "# raw image path\n",
    "train_img_raw_path = r'ws/images/train'\n",
    "test_img_raw_path = r'ws/images/test'\n",
    "\n",
    "# sample save path\n",
    "train_img_process_path = r'ws/images/train_crop_success'\n",
    "train_img_unprocess_path = r'ws/images/train_crop_fail'\n",
    "train_img_suspect_path = r'ws/images/train_crop_suspect'\n",
    "train_img_unread_path = r'cat1'\n",
    "train_img_undetect_path = r'cat2'\n",
    "train_img_lowconf_path = r'cat3'\n",
    "train_img_multiface_path = r'cat4'\n",
    "train_img_lowsimilar_path = r'cat5'\n",
    "test_img_process_path = 'ws/images/test_ready'\n",
    "test_img_suspect_path = 'ws/images/test_suspect'\n",
    "test_img_unprocess_path = 'ws/images/test_process_fail'\n",
    "\n",
    "# processed data folder\n",
    "train_img_data_path = r'ws/data/train'\n",
    "test_img_data_path = r'ws/data/test'\n",
    "\n",
    "# create directory for saving data\n",
    "create_preprocess_path(train_img_process_path, \\\n",
    "            train_img_suspect_path, train_img_lowconf_path, train_img_multiface_path, train_img_lowsimilar_path, \\\n",
    "            train_img_unprocess_path, train_img_unread_path, train_img_undetect_path, \\\n",
    "            test_img_process_path, test_img_unprocess_path, test_img_suspect_path, \\\n",
    "            train_img_data_path, test_img_data_path, dir_empty = False, parent_dir = docker_parent_dir)\n",
    "\n",
    "# turn off pandas 'chained assignment' error\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# haar cascade algorithm weights\n",
    "cascade_filename = 'ws/src/haarcascade_profileface.xml'\n",
    "\n",
    "# training results path\n",
    "training_results_path = r'ws/train_results/'\n",
    "training_model_save_path = r'train/model/'\n",
    "training_results_ckpt_path = r'train/checkpoint/'\n",
    "\n",
    "# create directory for saving data\n",
    "create_train_path(training_results_path, \\\n",
    "            training_model_save_path, training_results_ckpt_path, \\\n",
    "            dir_empty = False, parent_dir = docker_parent_dir)\n",
    "\n",
    "# pandas options\n",
    "pd.set_option('display.max_row', 20)\n",
    "pd.set_option('display.max_columns', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to utilize the pretrained feature extraction network of VGGFace2, get the input shape \n",
    "# load the feature extraction network\n",
    "feature_extract_net = VGGFace(model='resnet50', include_top = False, input_shape = (224, 224, 3), pooling = 'avg')\n",
    "\n",
    "# obtain the feature extract output dimension\n",
    "config_in = feature_extract_net.layers[0].input\n",
    "input_dim = config_in.shape\n",
    "input_dtype = config_in.dtype\n",
    "\n",
    "# read the label data using datatable package\n",
    "label_type_dt = dt.fread(label_dict_path, encoding = 'utf-8')\n",
    "label_type = label_type_dt.to_pandas().set_index('C0')\n",
    "label_type.rename(columns = {'C1':(label_type.loc[label_type.index.isnull()]).iloc[0,0]}, inplace = True)\n",
    "label_type = label_type.loc[label_type.index.notnull()]\n",
    "label_type.index = label_type.index.astype('int64')\n",
    "label_type.index.names = [None]\n",
    "\n",
    "train_label_dt = dt.fread(train_label_path, encoding = 'utf-8')\n",
    "train_label = train_label_dt.to_pandas().set_index('C0')\n",
    "train_label.rename(columns = {'C1':(train_label.loc[train_label.index.isnull()]).iloc[0,0]}, inplace = True)\n",
    "train_label.rename(columns = {'C2':(train_label.loc[train_label.index.isnull()]).iloc[0,1]}, inplace = True)\n",
    "train_label = train_label.loc[train_label.index.notnull()]\n",
    "train_label.index = train_label.index.astype('int64')\n",
    "train_label.index.names = [None]\n",
    "\n",
    "# mapping the label dictonary and train data set category\n",
    "label_dict = label_type.Category.to_dict()\n",
    "label_dict = dict(zip(label_dict.values(),label_dict.keys()))\n",
    "train_label.columns = [k.replace(' ','_') for k in train_label.columns]\n",
    "train_label['Category'] = train_label['Category'].map(label_dict)\n",
    "train_label['Category'] = train_label['Category'].astype(np.uint8)\n",
    "\n",
    "# create the status label to show the image status\n",
    "# (problmatic images: unreadable, undetectable, multiface/low confidence, low similarity)\n",
    "train_label['Status'] = np.zeros(train_label.shape[0],dtype = np.uint8)\n",
    "\n",
    "# import *.jpg image list from the selected folder\n",
    "train_img_raw_list = natsort.natsorted(glob.glob(os.path.join(train_img_raw_path,\"*.jpg\")))\n",
    "\n",
    "if len(train_img_raw_list) != train_label.shape[0]:\n",
    "    raise ValueError\n",
    "    \n",
    "# initialize MTCNN\n",
    "face_detector = MTCNN(min_face_size = 30, scale_factor = 0.809)\n",
    "\n",
    "# set the indices range to implement the pre-processing\n",
    "process_start = 0\n",
    "process_end = len(train_label)\n",
    "\n",
    "# create the numpy array to store the cropped_image (load part of it for test)\n",
    "cropped_image_data = np.empty((process_end-process_start,input_dim[1]*input_dim[2]*input_dim[3]), dtype = np.uint8)\n",
    "# cropped_image_label = train_label.copy()\n",
    "# cropped_image_label = cropped_image_label.iloc[list(range(process_start,process_end)),:]\n",
    "# cropped_image_label.drop(columns = ['Status','Category'], inplace = True)\n",
    "\n",
    "# drop out the indices of the training label that does not corresponds to the range\n",
    "train_label = train_label.iloc[list(range(process_start,process_end)),:]\n",
    "\n",
    "# iterate pre-processing for the all images in the directory\n",
    "for file_idx in tqdm(range(0,process_end-process_start)):\n",
    "\n",
    "    # load the image using opencv and get the file name\n",
    "    frame = cv2.imread(train_img_raw_list[process_start+file_idx])\n",
    "    file_name_split = os.path.split(train_img_raw_list[process_start+file_idx])\n",
    "\n",
    "    # categroize the image that cannot read\n",
    "    if frame is None:\n",
    "        try:\n",
    "            # use python image library if opencv fails\n",
    "            temp = Image.open(train_img_raw_list[process_start+file_idx])\n",
    "            frame = np.array(temp.convert(\"RGB\"))\n",
    "\n",
    "        except:\n",
    "            # if unable to open, categorize as 1\n",
    "            shutil.copy2(train_img_raw_list[process_start+file_idx], \\\n",
    "                         os.path.join(train_img_unprocess_path,train_img_unread_path,file_name_split[1]))\n",
    "            train_label['Status'][process_start+file_idx] = 1\n",
    "            cropped_image_data[file_idx,:] = np.zeros((input_dim[1]*input_dim[2]*input_dim[3]), dtype = np.uint8)\n",
    "\n",
    "    else:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # cv2 uses BGR -> RGB (will be converted to BGR later)\n",
    "        \n",
    "    # detect the face if the image has been read\n",
    "    if frame is not None:\n",
    "        results = face_detector.detect_faces(frame)\n",
    "\n",
    "        if len(results) == 0:\n",
    "            # (add later) another face detection algorithm (Harr Cascade from cv2)\n",
    "            shutil.copy2(train_img_raw_list[process_start+file_idx], \\\n",
    "                         os.path.join(train_img_unprocess_path,train_img_undetect_path,file_name_split[1]))\n",
    "            train_label['Status'][process_start+file_idx] = 2\n",
    "            cropped_image_data[file_idx,:] = np.zeros((input_dim[1]*input_dim[2]*input_dim[3]), dtype = np.uint8)\n",
    "            \n",
    "        else:\n",
    "            confidence_temp = [results[i]['confidence'] for i in range(len(results))]\n",
    "\n",
    "            # categorize and save the cropped images (separately if low confidentiality)\n",
    "            if len(results) == 1:\n",
    "                if results[0]['confidence'] >= 0.85:\n",
    "                    # normal case (single face + confidence > 85%) \n",
    "                    resized_face = cropface(frame, results, 0)\n",
    "                    \n",
    "                    # save image at the success folder (do not activate saving for actual train)\n",
    "                    cv2.imwrite(os.path.join(train_img_process_path,file_name_split[1]), \\\n",
    "                                cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "                    # Disable this line to speed up the code (the image file list is already sorted)\n",
    "                    # temp_idx = train_label.index[train_label['File_Name'] == file_name_split[1]].tolist()\n",
    "                    train_label['Status'][process_start+file_idx] = 0\n",
    "\n",
    "                    # save to the dataframe by converting the image to 1-D data\n",
    "                    cropped_image_data[file_idx,:] = np.ravel(resized_face).astype(np.uint8)\n",
    "\n",
    "                else:\n",
    "                    # low confidence (single face + confidence < 85%) \n",
    "                    resized_face = cropface(frame, results, 0)\n",
    "\n",
    "                    # save image at the suspect folder\n",
    "                    cv2.imwrite(os.path.join(train_img_suspect_path,train_img_lowconf_path, \\\n",
    "                                             file_name_split[1]),cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "                    train_label['Status'][process_start+file_idx] = 3\n",
    "                    cropped_image_data[file_idx,:] = np.ravel(resized_face.astype(np.uint8))\n",
    "                    \n",
    "            else:\n",
    "                # if multiple faces are detected\n",
    "                index_temp = [i for i in range(len(confidence_temp)) if confidence_temp[i] >= 0.85]\n",
    "                index_max = np.argmax(confidence_temp)\n",
    "\n",
    "                if len(index_temp) >= 1:\n",
    "\n",
    "                    # multiple face (multi-face + confidence >= 85%)\n",
    "                    for k in index_temp:\n",
    "                        resized_face = cropface(frame, results, k)\n",
    "\n",
    "                        # save image at the suspect folder\n",
    "                        file_name_temp = list(file_name_split[1])\n",
    "                        del file_name_temp[-4:]\n",
    "                        file_name_temp.extend([\"_\",str(k),\".jpg\"])\n",
    "                        file_name_temp = ''.join(file_name_temp)\n",
    "                        cv2.imwrite(os.path.join(train_img_suspect_path,train_img_multiface_path, \\\n",
    "                                                 file_name_temp),cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "                        if k == index_max:\n",
    "                            train_label['Status'][process_start+file_idx] = 4\n",
    "                            cropped_image_data[file_idx,:] = np.ravel(resized_face).astype(np.uint8)\n",
    "\n",
    "                else:\n",
    "                    # low confidence (multi-face + confidence < 85%) \n",
    "                    resized_face = cropface(frame, results, index_max)\n",
    "\n",
    "                    # save image at the suspect folder\n",
    "                    cv2.imwrite(os.path.join(train_img_suspect_path,train_img_lowconf_path, \\\n",
    "                                             file_name_split[1]),cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "                    train_label['Status'][process_start+file_idx] = 3\n",
    "                    cropped_image_data[file_idx,:] = np.ravel(resized_face).astype(np.uint8)\n",
    "                    \n",
    "# obtain the embedding vectors for the pretrained freature extraction network,\n",
    "# then the embedding vectors are compared by using cosine similarity\n",
    "# the feature extraction network already loaded\n",
    "\n",
    "# obtain the feature extract output dimension\n",
    "config_out = feature_extract_net.layers[-1].output\n",
    "embedding_dim = config_out.shape\n",
    "output_dtype = config_out.dtype\n",
    "\n",
    "# set the threshold for the cosine similarity \n",
    "similar_threshold = np.float32(0.3)\n",
    "\n",
    "# do this step for only the nominal images, eliminate problematic images\n",
    "drop_idx = train_label.index[train_label['Status'] == 2].tolist()+ \\\n",
    "            train_label.index[train_label['Status'] == 3].tolist()+ \\\n",
    "            train_label.index[train_label['Status'] == 4].tolist()\n",
    "drop_idx.sort()\n",
    "\n",
    "abs_drop_idx = [train_label.index.get_loc(i) for i in drop_idx]\n",
    "\n",
    "# copy the nominal images only and drop\n",
    "cropped_image_data_post = cropped_image_data.copy()\n",
    "# cropped_image_label = cropped_image_label.copy()\n",
    "train_label_post = train_label.copy()\n",
    "\n",
    "cropped_image_data_post = np.delete(cropped_image_data_post, abs_drop_idx, 0)\n",
    "# cropped_image_label.drop(index = drop_idx, inplace = True)\n",
    "train_label_post.drop(index = drop_idx, inplace = True)\n",
    "\n",
    "# obtain the feature extract output dimension\n",
    "config_out = feature_extract_net.layers[-1].output\n",
    "embedding_dim = config_out.shape\n",
    "output_dtype = config_out.dtype\n",
    "\n",
    "# set the threshold for the cosine similarity \n",
    "similar_threshold = np.float32(0.3)\n",
    "\n",
    "# categorize the item with respect to its label\n",
    "for k, v in label_dict.items():\n",
    "    \n",
    "    # get the data index that has a specific label\n",
    "    temp_idx = train_label_post.index[train_label_post['Category'] == v].tolist()\n",
    "    \n",
    "    abs_temp_idx = [train_label_post.index.get_loc(i) for i in temp_idx]\n",
    "\n",
    "    # for the normal image with the same label, compare the similarity\n",
    "    if len(temp_idx) > 1:\n",
    "       \n",
    "        # create the empty cosine similarity matrix\n",
    "        cos_similarity = np.empty((len(temp_idx),len(temp_idx)), dtype = np.float64)\n",
    "        \n",
    "        # get the image data\n",
    "        img_data_same_type_temp = cropped_image_data_post[abs_temp_idx,:]\n",
    "        img_data_same_type_temp_feature = np.empty((len(temp_idx),embedding_dim[1]),dtype = np.float64)\n",
    "\n",
    "        # apply the function\n",
    "        img_data_same_type_temp_feature = feature_extract_net.predict( \\\n",
    "                utils.preprocess_input(img_data_same_type_temp.astype(np.float64). \\\n",
    "                                       reshape((-1,input_dim[1],input_dim[2],input_dim[3])), version = 2))\n",
    "        \n",
    "        # get the combination\n",
    "        idx_comb = list(combinations(list(range(len(temp_idx))),2))\n",
    "        \n",
    "        # compute the similarity matrix\n",
    "        for temp_comb in idx_comb:    \n",
    "    \n",
    "            cos_similarity[temp_comb[0],temp_comb[1]] = \\\n",
    "            np.dot(img_data_same_type_temp_feature[temp_comb[0],:], \\\n",
    "                  img_data_same_type_temp_feature[temp_comb[1],:])/ \\\n",
    "            (np.linalg.norm(img_data_same_type_temp_feature[temp_comb[0],:])*\n",
    "             np.linalg.norm(img_data_same_type_temp_feature[temp_comb[1],:]))\n",
    "    \n",
    "            cos_similarity[temp_comb[1],temp_comb[0]] = \\\n",
    "            cos_similarity[temp_comb[0],temp_comb[1]]\n",
    "\n",
    "        # ignore diagonal entries\n",
    "        for diag_idx in list(range(len(temp_idx))):\n",
    "            cos_similarity[diag_idx,diag_idx] = 0\n",
    "\n",
    "        # categorize as problematic if images have too low similarity\n",
    "        avg_cos_similarity = cos_similarity.sum(axis = 1)/(len(cos_similarity)-1)\n",
    "        low_similarity_idx = [idx for idx, val in enumerate(avg_cos_similarity) if val <= similar_threshold]\n",
    "        \n",
    "        if len(low_similarity_idx) > 0:\n",
    "            for move_idx in low_similarity_idx:\n",
    "                \n",
    "                # change the status of the images with low similarity\n",
    "                train_label['Status'][temp_idx[move_idx]] = 5\n",
    "\n",
    "                # move image from the nominal folder to the suspect folder\n",
    "                file_name = train_label['File_Name'][temp_idx[move_idx]]\n",
    "\n",
    "                shutil.move(os.path.join(train_img_process_path,file_name), \\\n",
    "                            os.path.join(train_img_suspect_path,train_img_lowsimilar_path,file_name))\n",
    "\n",
    "# create the dataframe to store the cropped_image (load part of it for test)\n",
    "chunk_size = 10000\n",
    "num_chunks_raw = len(train_label) // chunk_size + 1  \n",
    "                \n",
    "# convert the raw data format to reduce the size (already np.uint8, but check once again)\n",
    "cropped_image_data = cropped_image_data.astype(dtype = np.uint8)\n",
    "\n",
    "# enumerating each chunk and save it as a file\n",
    "for idx, chunk in enumerate(np.array_split(cropped_image_data, num_chunks_raw)):\n",
    "    temp_file_name = 'cropped_image_data_'+str(idx)+'.csv'\n",
    "    temp_dframe = pd.DataFrame(data = chunk, index = list(range(process_start+idx*len(chunk), \\\n",
    "                                                                process_start+(idx+1)*len(chunk))))\n",
    "    temp_dframe.to_csv(os.path.join(train_img_data_path,temp_file_name), header = False)\n",
    "        \n",
    "train_label.to_csv(os.path.join(train_img_data_path,'train_label.csv'), header = False)\n",
    "\n",
    "with open(os.path.join(train_img_data_path,'label_dict.json'), 'w') as f: \n",
    "    json.dump(label_dict, f, indent = 4)\n",
    "    \n",
    "# drop out the problematic data and save them as dataframe format\n",
    "drop_idx_final = train_label.index[train_label['Status'] == 2].tolist()+ \\\n",
    "                 train_label.index[train_label['Status'] == 3].tolist()+ \\\n",
    "                 train_label.index[train_label['Status'] == 4].tolist()+ \\\n",
    "                 train_label.index[train_label['Status'] == 5].tolist()\n",
    "drop_idx_final.sort()\n",
    "\n",
    "abs_drop_idx_final = [train_label.index.get_loc(i) for i in drop_idx_final]\n",
    "\n",
    "if len(drop_idx_final) > 0:\n",
    "    x_train = np.delete(cropped_image_data, abs_drop_idx_final, 0)\n",
    "    y_train = train_label.copy()\n",
    "    y_train.drop(columns = ['Status'], inplace = True)\n",
    "    y_train = y_train.drop(index = drop_idx_final).reset_index(drop = True)\n",
    "    \n",
    "else:\n",
    "    x_train = cropped_image_data\n",
    "    y_train = pd.Series.to_frame(train_label['File_Name','Category'].copy())\n",
    "\n",
    "# create the dataframe to store the cropped_image (load part of it for test)\n",
    "num_chunks_xtrain = len(x_train) // chunk_size + 1\n",
    "    \n",
    "# convert the raw data format to reduce the size (already np.uint8, but check once again)\n",
    "x_train = x_train.astype(dtype = np.uint8)\n",
    "\n",
    "# enumerating each chunk and save it as afile\n",
    "for idx, chunk in enumerate(np.array_split(x_train, num_chunks_xtrain)):\n",
    "    temp_file_name = 'x_train_'+str(idx)+'.csv'\n",
    "    temp_dframe = pd.DataFrame(data = chunk, index = y_train.index[idx*len(chunk):(idx+1)*len(chunk)])\n",
    "    temp_dframe.to_csv(os.path.join(train_img_data_path,temp_file_name), header = False)\n",
    "    \n",
    "y_train.to_csv(os.path.join(train_img_data_path,'y_train.csv'), header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to utilize the pretrained feature extraction network of VGGFace2, get the input shape \n",
    "# load the feature extraction network\n",
    "feature_extract_net = VGGFace(model='resnet50', include_top = False, input_shape = (224, 224, 3), pooling = 'avg')\n",
    "\n",
    "# obtain the feature extract output dimension\n",
    "config_in = feature_extract_net.layers[0].input\n",
    "input_dim = config_in.shape\n",
    "input_dtype = config_in.dtype\n",
    "\n",
    "# import *.jpg image list from the selected folder\n",
    "test_img_raw_list = natsort.natsorted(glob.glob(os.path.join(test_img_raw_path,\"*.jpg\")))\n",
    "\n",
    "# opening label category dictionary JSON file\n",
    "with open(os.path.join(train_img_data_path,'label_dict.json')) as json_file:\n",
    "    label_dict = json.load(json_file)\n",
    "\n",
    "# get the maximum value in the dictionary\n",
    "get_v_label_dict = [v for k, v in label_dict.items()]\n",
    "max_idx = max(get_v_label_dict)\n",
    "\n",
    "# initialize MTCNN\n",
    "face_detector = MTCNN(min_face_size = 30, scale_factor = 0.809)\n",
    "\n",
    "# initialize haar cascade algorithm\n",
    "cascade = cv2.CascadeClassifier(cascade_filename)\n",
    "\n",
    "# set the indices range to implement the pre-processing\n",
    "process_start = 0\n",
    "process_end = len(test_img_raw_list)\n",
    "\n",
    "# create empty test label to save the identification result\n",
    "test_label_nominal = pd.DataFrame(columns = ['Category','Status','File_Name'], \\\n",
    "                                index = list(range(process_start,process_end)))\n",
    "test_label_suspect = pd.DataFrame(columns = ['Category','Status','File_Name'])\n",
    "\n",
    "# create the numpy array to store the cropped_image (load part of it for test)\n",
    "cropped_image_data = np.empty((process_end-process_start,input_dim[1]*input_dim[2]*input_dim[3]), dtype = np.uint8)\n",
    "cropped_image_data_suspect = np.empty((0,input_dim[1]*input_dim[2]*input_dim[3]), dtype = np.uint8)\n",
    "\n",
    "# iterate pre-processing for the all images in the directory\n",
    "for file_idx in tqdm(range(0,process_end-process_start)):\n",
    "\n",
    "    # load the image using opencv and get the file name\n",
    "    frame = cv2.imread(test_img_raw_list[process_start+file_idx])\n",
    "    file_name_split = os.path.split(test_img_raw_list[process_start+file_idx])\n",
    "\n",
    "    # categroize the image that cannot read\n",
    "    if frame is None:\n",
    "        try:\n",
    "            # use python image library if opencv fails\n",
    "            temp = Image.open(test_img_raw_list[process_start+file_idx])\n",
    "            frame = np.array(temp.convert(\"RGB\"))\n",
    "\n",
    "        except:\n",
    "            # if unable to open, make it as a black image, categorize it using random guess\n",
    "            shutil.copy2(test_image_raw_list[file_idx], \\\n",
    "                         os.path.join(test_img_unprocess_path,file_name_split[1]))\n",
    "            test_label_nominal['Status'][process_start+file_idx] = 1\n",
    "            test_label_nominal['Category'][process_start+file_idx] = 255\n",
    "            test_label_nominal['File_Name'][process_start+file_idx] = file_name_split[1]\n",
    "            cropped_image_data[file_idx,:] = np.zeros((req_img_dim[1]*req_img_dim[2]*req_img_dim[3]), \\\n",
    "                                                         dtype = np.uint8)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # cv2 uses BGR -> RGB (will be converted to BGR later)\n",
    "    \n",
    "    # detect the face if the image has been read\n",
    "    if frame is not None:\n",
    "        results = face_detector.detect_faces(frame)\n",
    "\n",
    "        # To be added:\n",
    "        # In case of multi face -> confidence sort and find matching face, check one-hot vectors \n",
    "        if len(results) == 0: \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) \n",
    "            results_l = cascade.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5, minSize = (30,30))\n",
    "            flipped = cv2.flip(gray,1)\n",
    "            results_r = cascade.detectMultiScale(flipped, scaleFactor = 1.3, minNeighbors = 5, minSize = (30,30))\n",
    "\n",
    "            if len(results_l) == 0 and len(results_r) == 0:\n",
    "                # if no face is detected, resize to the input size and save\n",
    "                resized_face = cv2.resize(frame, dsize = (input_dim[1],input_dim[2]), \\\n",
    "                                          interpolation = cv2.INTER_LINEAR)\n",
    "                \n",
    "            elif len(results_l) > 0:\n",
    "                x_bl_corner = results_r[0][0]\n",
    "                y_bl_corner = results_r[0][1] \n",
    "                box_width = results_r[0][2]\n",
    "                box_height = results_r[0][3]\n",
    "    \n",
    "                x_tr_corner = x_bl_corner+box_width\n",
    "                y_tr_corner = y_bl_corner+box_height\n",
    "\n",
    "                # get the bounding box image for the detected face\n",
    "                raw_face = frame[y_bl_corner:y_tr_corner, x_bl_corner:x_tr_corner]\n",
    "\n",
    "                # resize the image to conform the input size of VGGFace2 model \n",
    "                resized_face  = cv2.resize(raw_face, dsize = (224,224), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "            else:\n",
    "                x_bl_corner = results_r[0][0]\n",
    "                y_bl_corner = results_r[0][1] \n",
    "                box_width = results_r[0][2]\n",
    "                box_height = results_r[0][3]\n",
    "    \n",
    "                x_tr_corner = x_bl_corner+box_width\n",
    "                y_tr_corner = y_bl_corner+box_height\n",
    "\n",
    "                # get the bounding box image for the detected face\n",
    "                raw_face = frame[y_bl_corner:y_tr_corner, x_bl_corner:x_tr_corner]\n",
    "\n",
    "                # resize the image to conform the input size of VGGFace2 model \n",
    "                resized_face  = cv2.resize(raw_face, dsize = (224,224), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "            # save to the numpy array by converting the image to 1-D data\n",
    "            cropped_image_data[file_idx,:] = np.ravel(resized_face)\n",
    "            test_label_nominal['Status'][process_start+file_idx] = 2\n",
    "            test_label_nominal['Category'][process_start+file_idx] = max_idx+1\n",
    "            test_label_nominal['File_Name'][process_start+file_idx] = file_name_split[1]\n",
    "            cv2.imwrite(os.path.join(test_img_process_path,file_name_split[1]), \\\n",
    "                        cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        elif len(results) == 1:\n",
    "            resized_face = cropface(frame, results, 0)\n",
    "                \n",
    "            # save image at the success folder\n",
    "            cv2.imwrite(os.path.join(test_img_process_path,file_name_split[1]), \\\n",
    "                        cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "            # set it as nominal image\n",
    "            test_label_nominal['Status'][process_start+file_idx] = 0\n",
    "            test_label_nominal['Category'][process_start+file_idx] = max_idx+1\n",
    "            test_label_nominal['File_Name'][process_start+file_idx] = file_name_split[1]\n",
    "            # save to the dataframe by converting the image to 1-D data\n",
    "            cropped_image_data[file_idx,:] = np.ravel(resized_face).astype(np.uint8)\n",
    "            \n",
    "        else:\n",
    "            # confidence level array\n",
    "            confidence_temp = [results[i]['confidence'] for i in range(len(results))]\n",
    "            # if multiple faces are detected and its confidence is larger than/equal to 85%\n",
    "            index_temp = [i for i in range(len(confidence_temp)) if confidence_temp[i] >= 0.85]\n",
    "            index_max = np.argmax(confidence_temp)\n",
    "            \n",
    "            # multiple face (multi-face + confidence >= 85%)\n",
    "            for k in index_temp:\n",
    "                resized_face = cropface(frame, results, k)\n",
    "                # save image at the suspect folder\n",
    "                file_name_temp = list(file_name_split[1])\n",
    "                del file_name_temp[-4:]\n",
    "                file_name_temp.extend([\"_\",str(k),\".jpg\"])\n",
    "                file_name_temp = ''.join(file_name_temp)\n",
    "                cv2.imwrite(os.path.join(test_img_suspect_path, file_name_temp), \\\n",
    "                            cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                test_label_suspect = test_label_suspect.append \\\n",
    "                ({'Category': max_idx+1, 'Status': 4, 'File_Name': file_name_split[1]}, ignore_index=True)\n",
    "                cropped_image_data_suspect = np.vstack((cropped_image_data_suspect, \\\n",
    "                                                        np.ravel(resized_face).astype(np.uint8)))\n",
    "                \n",
    "                if k == index_max:\n",
    "                    # save this image at the success folder\n",
    "                    cv2.imwrite(os.path.join(test_img_process_path,file_name_split[1]), \\\n",
    "                                cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR))\n",
    "                    test_label_nominal['Status'][process_start+file_idx] = 4\n",
    "                    test_label_nominal['Category'][process_start+file_idx] = max_idx+1\n",
    "                    test_label_nominal['File_Name'][process_start+file_idx] = file_name_split[1]\n",
    "                    # save to the dataframe by converting the image to 1-D data\n",
    "                    cropped_image_data[file_idx,:] = np.ravel(resized_face).astype(np.uint8)\n",
    "                    \n",
    "# convert the raw data format to reduce the size\n",
    "cropped_image_data = cropped_image_data.astype(dtype = 'uint8')\n",
    "test_label_nominal = test_label_nominal.astype({'Category':np.uint8, 'Status':np.uint8})\n",
    "\n",
    "# create the dataframe to store the cropped_image (load part of it for test)\n",
    "chunk_size = 5000\n",
    "num_chunks_raw = len(test_label_nominal) // chunk_size + 1\n",
    "\n",
    "# enumerating each chunk and save it as afile\n",
    "for idx, chunk in enumerate(np.array_split(cropped_image_data, num_chunks_raw)):\n",
    "    temp_file_name = 'cropped_image_data_nominal_'+str(idx)+'.csv'\n",
    "    temp_dframe = pd.DataFrame(data = chunk, index = list(range(process_start+idx*len(chunk), \\\n",
    "                                                                process_start+(idx+1)*len(chunk))))\n",
    "    temp_dframe.to_csv(os.path.join(test_img_data_path,temp_file_name), header = False)\n",
    "        \n",
    "test_label_nominal.to_csv(os.path.join(test_img_data_path,'test_label_nominal_empty.csv'), header = False)\n",
    "\n",
    "# create the dataframe to store the cropped_image (load part of it for test)\n",
    "num_chunks_suspect = len(test_label_suspect) // chunk_size + 1\n",
    "\n",
    "# enumerating each chunk and save it as afile\n",
    "for idx, chunk in enumerate(np.array_split(cropped_image_data_suspect, num_chunks_suspect)):\n",
    "    temp_file_name = 'cropped_image_data_suspect_'+str(idx)+'.csv'\n",
    "    temp_dframe = pd.DataFrame(data = chunk, index = list(range(process_start+idx*len(chunk), \\\n",
    "                                                                process_start+(idx+1)*len(chunk))))\n",
    "    temp_dframe.to_csv(os.path.join(test_img_data_path,temp_file_name), header = False)\n",
    "        \n",
    "test_label_suspect.to_csv(os.path.join(test_img_data_path,'test_label_suspect_empty.csv'), header = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "create layers (preprocessing layers + VGGFace + fc layers) \\\n",
    "load the training data \\\n",
    "training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # clear the session to prevent the system from memory leak\n",
    "K.clear_session()\n",
    "\n",
    "# load only feature extraction\n",
    "pretrained_base = VGGFace(model = 'resnet50', include_top = False, input_shape = (224, 224, 3), pooling = 'avg')\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "# pre-processing layers\n",
    "preprocessing = Sequential(name = 'preprocessing')\n",
    "preprocessing.add(RandomTranslation(height_factor = 0.35, width_factor = 0.35, input_shape = (224, 224, 3)))\n",
    "preprocessing.add(RandomRotation(factor = 0.166))\n",
    "preprocessing.add(RandomFlip(mode = \"horizontal\"))\n",
    "preprocessing.add(RandomZoom(height_factor = 0.4, width_factor = 0.4))\n",
    "preprocessing.add(RandomContrast(factor = 0.3))\n",
    "\n",
    "# fc layers\n",
    "fc = Sequential(name = 'fc')\n",
    "fc.add(Flatten())\n",
    "fc.add(Dense(1024, activation = 'relu'))\n",
    "fc.add(Dropout(0.2))\n",
    "fc.add(Dense(100, activation = 'softmax'))\n",
    "\n",
    "# add the fully connected to the pretrained feature extraction base network\n",
    "model = Sequential()\n",
    "model.add(preprocessing)\n",
    "model.add(pretrained_base)\n",
    "model.add(fc)\n",
    "\n",
    "# learning rate scheduler\n",
    "lr_scheduler = lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate = 1e-3,decay_steps = 500, decay_rate = 0.90, staircase = True)\n",
    "# CosineDecayRestarts(initial_learning_rate = 5e-4, first_decay_steps = 1000, t_mul = 2.0, m_mul = 1.0, alpha = 0.01)\n",
    "# CosineDecay(initial_learning_rate = 5e-4, decay_steps = 10000, alpha = 0.02)\n",
    "\n",
    "opt_alg = Adam(learning_rate = lr_scheduler)\n",
    "# SGD(learning_rate = lr_scheduler, momentum = 0.9)\n",
    "\n",
    "# set the learning process through compile step\n",
    "model.compile(\n",
    "    loss = CategoricalCrossentropy(),  \n",
    "    optimizer = opt_alg,\n",
    "    metrics = ['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the feature extract output dimension\n",
    "config_in = model.layers[0].input\n",
    "input_dim = config_in.shape\n",
    "\n",
    "# read the saved data in csv format\n",
    "# using datatable package\n",
    "y_pre_dt = dt.fread(os.path.join(train_img_data_path,'y_train.csv'), encoding = 'utf-8')\n",
    "y_pre = y_pre_dt['C2'].to_numpy()\n",
    "\n",
    "x_pre_raw_list = natsort.natsorted(glob.glob(os.path.join(train_img_data_path,\"x_train_*.csv\")))\n",
    "x_pre = np.empty((len(y_pre),input_dim[1]*input_dim[2]*input_dim[3]+1), dtype = np.uint8)\n",
    "\n",
    "temp_ridx = 0\n",
    "for file in x_pre_raw_list:\n",
    "    x_pre_temp_dt = dt.fread(file, encoding = 'utf-8')\n",
    "    x_pre_temp = x_pre_temp_dt.to_numpy()\n",
    "    x_pre[temp_ridx:temp_ridx+len(x_pre_temp),:] = x_pre_temp\n",
    "    temp_ridx = temp_ridx+len(x_pre_temp)\n",
    "        \n",
    "# check the data integrity (shuffled index check)\n",
    "if x_pre.shape[0] != y_pre.shape[0]:\n",
    "    raise ValueError\n",
    "\n",
    "train_img_process_list = natsort.natsorted(glob.glob(os.path.join(train_img_process_path,\"*.jpg\")))\n",
    "train_img_files_list = []\n",
    "    \n",
    "for file in train_img_process_list:\n",
    "    file_name_split = os.path.split(file)\n",
    "    file_name_temp = list(file_name_split[1])\n",
    "    del file_name_temp[-4:]\n",
    "    train_img_files_list.append(int(\"\".join(file_name_temp)))\n",
    "    \n",
    "integrity_check_list = y_pre_dt['C1'].to_list()\n",
    "integrity_check_list = integrity_check_list[0]\n",
    "\n",
    "for idx in range(len(integrity_check_list)):\n",
    "    file_name_temp = list(integrity_check_list[idx])\n",
    "    del file_name_temp[-4:]\n",
    "    integrity_check_list[idx] = int(\"\".join(file_name_temp))\n",
    "    \n",
    "if (integrity_check_list != train_img_files_list):\n",
    "    raise ValueError  \n",
    "\n",
    "# remove the photo indices, change the file format and shuffle\n",
    "x_pre = x_pre[:,1:]\n",
    "y_pre = y_pre\n",
    "\n",
    "[x_train, x_valid, y_train, y_valid] = train_test_split(x_pre, y_pre, test_size = 0.10, shuffle = True)\n",
    "\n",
    "# reshape for the training process\n",
    "x_train = x_train.reshape((-1,input_dim[1],input_dim[2],input_dim[3])).astype(np.float32)\n",
    "x_valid = x_valid.reshape((-1,input_dim[1],input_dim[2],input_dim[3])).astype(np.float32)\n",
    "\n",
    "# testing one-hot-encoding (wrong accuracy computation in sparse categorical crossentropy)\n",
    "onehot = OneHotEncoder(sparse = False)\n",
    "onehot.fit(y_train)\n",
    "y_train = onehot.transform(y_train)\n",
    "y_valid = onehot.transform(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: RGB to BGR conversion is automatically implemented by utils.preprocess_input\n",
    "# vggface_resnet50 uses BGR type format as input; cv2 already read the image in BGR (pyplot adopts RGB format)\n",
    "# data_format = K.image_data_format()\n",
    "# print(data_format)\n",
    "x_train = utils.preprocess_input(x_train, version = 2)\n",
    "x_valid = utils.preprocess_input(x_valid, version = 2)\n",
    "\n",
    "train_tensor = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_tensor = train_tensor.batch(batch_size = 32, drop_remainder = False, num_parallel_calls = None)\n",
    "validation_tensor = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "validation_tensor = validation_tensor.batch(batch_size = 32, drop_remainder = False, num_parallel_calls = None)\n",
    "\n",
    "md_check_callback = tf.keras.callbacks.ModelCheckpoint(filepath = training_results_path+training_results_ckpt_path,\n",
    "                                                    monitor = 'val_categorical_accuracy',\n",
    "                                                    verbose = 1,\n",
    "                                                    save_best_only = True,\n",
    "                                                    save_weights_only = True,\n",
    "                                                    mode = 'auto',\n",
    "                                                    save_freq = 'epoch',\n",
    "                                                    initial_value_threshold = None)\n",
    "\n",
    "history = model.fit(train_tensor, epochs = 15, validation_data = validation_tensor, callbacks = md_check_callback)\n",
    "model.save(training_results_path+training_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "load the test dataset \\\n",
    "create the submission labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained model\n",
    "if os.path.isdir(training_results_path+training_model_save_path):\n",
    "    trained_model = keras.models.load_model(training_results_path+training_model_save_path[:-1])\n",
    "\n",
    "# pop up the pre-processing layer\n",
    "model = Sequential()\n",
    "model.add(trained_model.layers[1])\n",
    "model.add(trained_model.layers[2])\n",
    "model.summary()\n",
    "    \n",
    "# obtain the feature extract output dimension\n",
    "config_in = model.layers[0].input\n",
    "input_dim = config_in.shape\n",
    "\n",
    "# read the saved data in csv format\n",
    "# using datatable package\n",
    "test_label_nominal_empty = dt.fread(os.path.join(test_img_data_path,'test_label_nominal_empty.csv'), \\\n",
    "                                    encoding = 'utf-8')\n",
    "test_label_nominal_empty = test_label_nominal_empty.to_pandas()\n",
    "test_label_suspect_empty = dt.fread(os.path.join(test_img_data_path,'test_label_suspect_empty.csv'), \\\n",
    "                                    encoding = 'utf-8')\n",
    "test_label_suspect_empty = test_label_suspect_empty.to_pandas()\n",
    "\n",
    "cropped_image_data_nominal_list = natsort.natsorted(glob.glob(os.path.join(test_img_data_path, \\\n",
    "                                                                   \"cropped_image_data_nominal_*.csv\")))\n",
    "cropped_image_data_nominal = np.empty((len(test_label_nominal_empty),input_dim[1]*input_dim[2]*input_dim[3]), \n",
    "                              dtype = np.float32)\n",
    "\n",
    "temp_ridx = 0\n",
    "for file in cropped_image_data_nominal_list:\n",
    "    cropped_image_data_nominal_temp_dt = dt.fread(file, encoding = 'utf-8')\n",
    "    cropped_image_data_nominal_temp = cropped_image_data_nominal_temp_dt.to_numpy()\n",
    "    cropped_image_data_nominal[temp_ridx:temp_ridx+len(cropped_image_data_nominal_temp),:] = \\\n",
    "    cropped_image_data_nominal_temp[:,1:]\n",
    "    temp_ridx = temp_ridx+len(cropped_image_data_nominal_temp)\n",
    "\n",
    "del globals()['cropped_image_data_nominal_temp_dt']\n",
    "del globals()['cropped_image_data_nominal_temp']\n",
    "\n",
    "cropped_image_data_suspect_list = natsort.natsorted(glob.glob(os.path.join(test_img_data_path, \\\n",
    "                                                                   \"cropped_image_data_suspect_*.csv\")))\n",
    "cropped_image_data_suspect = np.empty((len(test_label_suspect_empty),input_dim[1]*input_dim[2]*input_dim[3]), \n",
    "                              dtype = np.float32)\n",
    "\n",
    "temp_ridx = 0\n",
    "for file in cropped_image_data_suspect_list:\n",
    "    cropped_image_data_suspect_temp_dt = dt.fread(file, encoding = 'utf-8')\n",
    "    cropped_image_data_suspect_temp = cropped_image_data_suspect_temp_dt.to_numpy()\n",
    "    cropped_image_data_suspect[temp_ridx:temp_ridx+len(cropped_image_data_suspect_temp),:] = \\\n",
    "    cropped_image_data_suspect_temp[:,1:]\n",
    "    temp_ridx = temp_ridx+len(cropped_image_data_suspect_temp)\n",
    "\n",
    "del globals()['cropped_image_data_suspect_temp_dt']\n",
    "del globals()['cropped_image_data_suspect_temp']\n",
    "\n",
    "# add probability measure for the multiple faces cases\n",
    "test_label_suspect_empty['Prob'] = np.float32(0.0)\n",
    "    \n",
    "# make prediction using the trained model\n",
    "for idx in tqdm(range(len(test_label_nominal_empty))):\n",
    "    if test_label_nominal_empty['C2'][idx] == 0:\n",
    "        temp_reformat = cropped_image_data_nominal[idx,:].reshape((-1,input_dim[1],input_dim[2],input_dim[3]))\n",
    "        temp_result = model.predict(utils.preprocess_input(temp_reformat, version = 2))\n",
    "        test_label_nominal_empty['C1'][idx] = np.argmax(temp_result)\n",
    "        \n",
    "    elif test_label_nominal_empty['C2'][idx] == 1:\n",
    "        test_label_nominal_empty['C1'][idx] = random.randrange(0,100)\n",
    "        \n",
    "    elif test_label_nominal_empty['C2'][idx] == 2:\n",
    "        temp_reformat = cropped_image_data_nominal[idx,:].reshape((-1,input_dim[1],input_dim[2],input_dim[3]))\n",
    "        temp_result = model.predict(utils.preprocess_input(temp_reformat, version = 2))\n",
    "        test_label_nominal_empty['C1'][idx] = np.argmax(temp_result)\n",
    "        \n",
    "    else:\n",
    "        suspect_idx_temp = test_label_suspect_empty.index[test_label_suspect_empty['C3'] == \\\n",
    "                                                          test_label_nominal_empty['C3'][idx]]\n",
    "        \n",
    "        # integrity check\n",
    "        if sum(cropped_image_data_nominal[idx,:]-cropped_image_data_suspect[suspect_idx_temp[0],:]) != 0:\n",
    "            raise ValueError\n",
    "        \n",
    "        for sub_idx in suspect_idx_temp:\n",
    "            temp_reformat = cropped_image_data_suspect[sub_idx,:]. \\\n",
    "                                reshape((-1,input_dim[1],input_dim[2],input_dim[3]))\n",
    "            temp_result = model.predict(utils.preprocess_input(temp_reformat, version = 2))\n",
    "            test_label_suspect_empty['C1'][sub_idx] = np.argmax(temp_result)\n",
    "            test_label_suspect_empty['Prob'][sub_idx] = np.max(temp_result)\n",
    "            \n",
    "        max_idx = np.argmax(test_label_suspect_empty['Prob'][suspect_idx_temp])\n",
    "        test_label_nominal_empty['C1'][idx] = test_label_suspect_empty['C1'][suspect_idx_temp[max_idx]]\n",
    "\n",
    "# save the current labeled data\n",
    "test_label_nominal_empty.drop(columns = ['C0'], inplace = True)\n",
    "test_label_suspect_empty.drop(columns = ['C0'], inplace = True)\n",
    "test_label_nominal_empty.to_csv(os.path.join(test_img_data_path,'test_label_nominal.csv'), header = False)\n",
    "test_label_suspect_empty.to_csv(os.path.join(test_img_data_path,'test_label_suspect.csv'), header = False)\n",
    "\n",
    "# save the submission data by mapping the numerical category to the name\n",
    "submission_label = pd.DataFrame(data = test_label_nominal_empty['C1'][:].to_numpy(), \\\n",
    "                                index = test_label_nominal_empty.index, columns = ['Category']) \n",
    "\n",
    "label_rev_type = pd.read_json(os.path.join(train_img_data_path,'label_dict.json'), typ = 'series')\n",
    "label_rev_dict = label_rev_type.to_dict()\n",
    "label_rev_dict = dict(zip(label_rev_dict.values(),label_rev_dict.keys()))\n",
    "\n",
    "submission_label['Category'] = submission_label['Category'].map(label_rev_dict)\n",
    "submission_label.index.name = 'Id'\n",
    "\n",
    "submission_label.to_csv(os.path.join(test_label_path,'submission_label.csv'), header = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
